{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwUz5hwWhYHO"
      },
      "outputs": [],
      "source": [
        "!pip install rouge tf-estimator-nightly==2.8.0.dev2021122109 simplet5 folium==0.2.1 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from random import sample\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import os\n",
        "import torch\n",
        "import json \n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
        "from random import sample\n",
        "from rouge import Rouge"
      ],
      "metadata": {
        "id": "DEb2ULFwhsee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S08a83xMhwrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/cnn_dailymail'\n",
        "path = os.path.join(DATA_PATH, 'train.csv')\n",
        "training_df = pd.read_csv(path, engine='python', error_bad_lines=False)\n",
        "\n",
        "MAX_LEN = 512\n",
        "SUMMARY_LEN = 150\n",
        "TRAINING_SIZE = 5000\n",
        "\n",
        "training_df = training_df.iloc[0:TRAINING_SIZE,:].copy()\n",
        "training_article_ls = list(training_df['article'])\n",
        "training_highlight_ls = list(training_df['highlights'])\n",
        "\n",
        "df = pd.DataFrame(columns=['target_text','source_text'])\n",
        "df['target_text'] = training_highlight_ls\n",
        "df['source_text'] = ['summarize: '+item for item in training_article_ls]"
      ],
      "metadata": {
        "id": "7cznPJDah1kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = simplet5.SimpleT5()\n",
        "\n",
        "model.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\n",
        "\n",
        "MAX_EPOCHS = 10\n",
        "\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "\n",
        "model.train(\n",
        "    train_df = df[0:(int)(0.7*TRAINING_SIZE)],\n",
        "    eval_df = df[(int)(0.7*TRAINING_SIZE):TRAINING_SIZE], \n",
        "    source_max_token_len = MAX_LEN, \n",
        "    target_max_token_len = SUMMARY_LEN, \n",
        "    batch_size = 2, \n",
        "    max_epochs = MAX_EPOCHS, \n",
        "    use_gpu = True\n",
        "    )\n",
        "            \n",
        "model_path = ''\n",
        "rootdir = 'outputs/'\n",
        "for it in os.scandir(rootdir):\n",
        "    if it.is_dir():\n",
        "        if 't5-epoch-' + (str)(MAX_EPOCHS-1) in it.path:\n",
        "            model_path = it.path\n",
        "            print(model_path)"
      ],
      "metadata": {
        "id": "0ii-tJalh8sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "\n",
        "# UNCOMMENT IF RUNNING ONLY EVALUATION ON OUTPUT SAMPLES\n",
        "# model.load_model(\"t5\",\"./\" + model_path , use_gpu=True)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Sampling on 10 articles\n",
        "for index in sample(list(np.arange(len(training_articles))), 10):\n",
        "    rouge = Rouge()\n",
        "    prediction = model.predict(training_article_ls[index])\n",
        "\n",
        "    r_score = rouge.get_scores(prediction, training_highlight_ls[index])"
      ],
      "metadata": {
        "id": "GMnxAfVziWJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}